{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406cdf1a-e167-49d4-a7a7-54479104257e",
   "metadata": {},
   "source": [
    "## Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16ffac-22fc-4a47-aa34-fd21ccc26c3e",
   "metadata": {},
   "source": [
    "link to dataset: https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8afa248-9436-455f-baa2-262eae143ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12f70d41-4115-4d85-85d6-72c67110e533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "Testing Data:\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_df = pd.read_csv('titanic/train.csv')\n",
    "\n",
    "# Load the testing data\n",
    "test_df = pd.read_csv('titanic/test.csv')\n",
    "\n",
    "# Display the first few rows of each dataset to verify they loaded correctly\n",
    "print(\"Training Data:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTesting Data:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87998bfb-8a85-48d7-b1f3-45f1b4ab141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the training data\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the testing data\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58f43222-fb53-43a7-ab4f-be86f6abcf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "def fill_missing(df, cols, method='median'):\n",
    "    for col in cols:\n",
    "        if method == 'median':\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        elif method == 'mode':\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Apply fill_missing\n",
    "fill_missing(train_df, ['Age', 'Fare'])\n",
    "fill_missing(test_df, ['Age', 'Fare'])\n",
    "fill_missing(train_df, ['Embarked'], method='mode')\n",
    "fill_missing(test_df, ['Embarked'], method='mode')\n",
    "\n",
    "# Fill 'Cabin' column with 'Unknown' for consistency\n",
    "train_df['Cabin'] = train_df['Cabin'].fillna('Unknown')\n",
    "test_df['Cabin'] = test_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Encode 'Sex' column\n",
    "train_df['Sex'] = (train_df['Sex'] == 'female').astype(int)\n",
    "test_df['Sex'] = (test_df['Sex'] == 'female').astype(int)\n",
    "\n",
    "# Final data initialization and scaling\n",
    "features = ['Sex', 'Age', 'Fare']\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['Survived']\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1030d6c0",
   "metadata": {},
   "source": [
    "## kNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8855e5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction on Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79       444\n",
      "           1       0.70      0.39      0.50       268\n",
      "\n",
      "    accuracy                           0.71       712\n",
      "   macro avg       0.71      0.64      0.65       712\n",
      "weighted avg       0.71      0.71      0.68       712\n",
      "\n",
      "[[400  44]\n",
      " [164 104]]\n",
      "Model Prediction on Validation Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80       105\n",
      "           1       0.82      0.42      0.55        74\n",
      "\n",
      "    accuracy                           0.72       179\n",
      "   macro avg       0.76      0.68      0.68       179\n",
      "weighted avg       0.74      0.72      0.70       179\n",
      "\n",
      "[[98  7]\n",
      " [43 31]]\n"
     ]
    }
   ],
   "source": [
    "# Train kNN Model\n",
    "model = KNeighborsClassifier(27)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "print(\"Model Prediction on Training Data\")\n",
    "print(metrics.classification_report(y_train, y_train_pred))\n",
    "print(metrics.confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "print(\"Model Prediction on Validation Data\")\n",
    "print(metrics.classification_report(y_val, y_val_pred))\n",
    "print(metrics.confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ec9cbef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Embarked\n- Parch\n- Pclass\n- SibSp\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Testing data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m test_df[features]\n\u001b[0;32m----> 3\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Selecting 20 random passengers to analyze their survival probabilities\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1043\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1040\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1042\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m-> 1043\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Embarked\n- Parch\n- Pclass\n- SibSp\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7020042",
   "metadata": {},
   "source": [
    "### Gender\n",
    "The gender of the passengers, which is defined as 0 for male and 1 for female, is an indicator of survival probability for the dataset under the k-Nearest Neighbors model. By analyzing the data, we can see that all of the females have a higher survival probability than all of the males. The lowest survival probability among women was 0.518519, while the highest survival probability for men was only 0.333333.\n",
    "\n",
    "### Age\n",
    "Age is less of an indicator of survival probability for the dataset under the k-Nearest Neighbors model. As the data shows, there are relatively similar clusters of age both at the higher and lower proabilities for survival. While it is slightly more likely for a younger person to have a higher rate of survival, there are also some potential outliers within the randomly selected dataset that do not give much strength to this claim.\n",
    "\n",
    "### Fare\n",
    "The fare of the passengers is a good indicator of survival rate based on the k-Nearest Neighbors model. From the random testing selection, we can see that the lower fares paid tended to have a lower survival probability. On the other hand, the higher fares were more likely to have higher survival probabilities. In particular, the largest value within this selection was a significantly higher fare and survival probability than the rest of the passengers (134.5 farte and 0.925926 survival probability)\n",
    "\n",
    "### Concluding Remarks\n",
    "The k-Nearest Neighbors model shows a trend of higher survival rates among females and those that paid higher fares. There is a small indication for higher proability in passengers with lower ages, however, this is not a very strong indicator of survival probability for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3465ceca-67e0-4595-8f01-575cbf0956eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.776536312849162\n",
      "Precision: 0.7125\n",
      "Recall: 0.7702702702702703\n",
      "F1 Score: 0.7402597402597403\n",
      "Confusion Matrix:\n",
      " [[82 23]\n",
      " [17 57]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       105\n",
      "           1       0.71      0.77      0.74        74\n",
      "\n",
      "    accuracy                           0.78       179\n",
      "   macro avg       0.77      0.78      0.77       179\n",
      "weighted avg       0.78      0.78      0.78       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select relevant features and the target variable\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "target = 'Survived'\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for feature in ['Sex', 'Embarked']:\n",
    "    train_df[feature] = le.fit_transform(train_df[feature])\n",
    "    test_df[feature] = le.transform(test_df[feature])\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X = train_df[features]\n",
    "y = train_df[target]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = nb.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred))\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_pred = nb.predict(test_df[features])\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': test_pred\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f4a0c-5025-4a56-9622-54f70efd8406",
   "metadata": {},
   "source": [
    "### Detailed Report for Naive Bayes\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "This report evaluates the performance of a Gaussian Naive Bayes model trained on the Titanic dataset to predict whether a passenger survived. The model was trained using the training set and validated using a validation set comprising 20% of the training data. Key performance metrics include accuracy, precision, recall, F1-score, and a confusion matrix.\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "The accuracy of the model is 77.65%. This means that approximately 77.65% of the predictions made by the model on the validation set are correct. While accuracy provides a general sense of the model's performance, it does not differentiate between the types of errors made.\n",
    "\n",
    "#### Precision\n",
    "\n",
    "Precision for the positive class (survived) is 71.25%. This metric indicates that when the model predicts a passenger survived, it is correct 71.25% of the time. Precision is crucial in scenarios where false positives are costly.\n",
    "\n",
    "#### Recall\n",
    "\n",
    "Recall for the positive class (survived) is 77.03%. This metric measures the model's ability to correctly identify passengers who survived. A recall of 77.03% means that the model successfully identified 77.03% of the actual survivors.\n",
    "\n",
    "#### F1 Score\n",
    "\n",
    "The F1 score is the harmonic mean of precision and recall. For the positive class, the F1 score is 74.03%. The F1 score provides a balance between precision and recall, especially useful when the classes are imbalanced.\n",
    "\n",
    "#### Confusion Matrix\n",
    "\n",
    "The confusion matrix provides a detailed breakdown of the model's predictions:\n",
    "- True Negatives (TN): 82\n",
    "- False Positives (FP): 23\n",
    "- False Negatives (FN): 17\n",
    "- True Positives (TP): 57\n",
    "\n",
    "From the confusion matrix, we observe that:\n",
    "- The model correctly identified 82 passengers who did not survive (true negatives).\n",
    "- The model incorrectly predicted that 23 passengers survived when they did not (false positives).\n",
    "- The model missed 17 passengers who survived (false negatives).\n",
    "- The model correctly identified 57 passengers who survived (true positives).\n",
    "\n",
    "#### Classification Report\n",
    "\n",
    "The classification report provides precision, recall, and F1-score for each class (0: Did not survive, 1: Survived):\n",
    "- Class 0 (Did not survive): Precision = 83%, Recall = 78%, F1-score = 80%\n",
    "- Class 1 (Survived): Precision = 71%, Recall = 77%, F1-score = 74%\n",
    "\n",
    "The weighted averages for these metrics account for class imbalances, providing an overall view of model performance.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The Gaussian Naive Bayes model shows reasonable performance with an overall accuracy of 77.65%. It demonstrates a good balance between precision (71.25%) and recall (77.03%) for predicting passenger survival. The F1 score (74.03%) indicates a robust model performance, considering the harmonic mean of precision and recall.\n",
    "\n",
    "To further improve the model, additional feature engineering, hyperparameter tuning, or employing more sophisticated models could be explored. Nonetheless, the current model provides a solid foundation for predicting passenger survival on the Titanic dataset.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **Feature Engineering**: Explore additional features or interactions between existing features to provide the model with more relevant information.\n",
    "2. **Hyperparameter Tuning**: Although Naive Bayes has few hyperparameters, exploring different configurations or variations (e.g., Bernoulli Naive Bayes) may yield better results.\n",
    "3. **Ensemble Methods**: Combining the predictions of multiple models (e.g., using a voting classifier) could improve overall performance.\n",
    "4. **Cross-Validation**: Implementing cross-validation during model training can provide more reliable performance estimates and help prevent overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
